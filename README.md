# ASTR 502 Data Mining and Machine Learning in Astronomy

## Location

Steward **R208** or Zoom : https://arizona.zoom.us/j/6849448207

## Textbook

Dive into Deep Learning (https://d2l.ai)

## Class Schedule

| ID |  Day |     Topic     |   Materials   | Presenters | Notes |
|----|------|---------------|---------------|------------|-------|
|  1 | 1/12 | Course Introduction          | | Tim | |
|  2 | 1/19 | Overview of Machine Learning | | Hung-Jin |[slides](./slides/ML_overview.pdf) |
|  3 | 1/24 | ML Applications in Astro | | Tim | 
|  4 | 1/26 | Gaussian Processes and NNs to sample parameter spaces quickly | | Supranta| 
|  5 | 1/31 | Linear Regression (theory & implementation) | d2l 3.1-3.3 | Wei Leong | [notebook](./notebooks/lec05_linear_regression_20220131/lec05_linear_regression_20220131.ipynb)|
|  6 | 2/2 | Logistic/Softmax Regression (theory & implementation) | d2l [§3.4](./d2l_briefs/3.4_softmax-regression.md), 3.5-3.7 | Chia-Lin | [slides](./slides/lec06_softmass_regression_20220202.pdf)|
|  7 | 2/7 | Multilayer Perceptrons | d2l [§4.1](./d2l_briefs/4.1_multilayer-perceptrons.md), 4.2, 4.3 <br> [notebook: MLP](./notebooks/[demo]%20pytorch%20softmax%20regression%20&%20MLP.ipynb)| Hina | [slides](https://docs.google.com/presentation/d/1zcgrALOXQZUYljuE4Y11QCcYA3UOW0iSjwpC_4bVtEQ/edit?usp=sharing) |
|  8 | 2/9 | Model Selection, Underfitting & Overfitting, Weight Decay, Dropout | d2l [§4.4](./d2l_briefs/4.4_model-selection.md), [§4.5](./d2l_briefs/4.5_weight-decay.md), [§4.6](./d2l_briefs/4.6_dropout.md) <br> [notebook: dropout](./notebooks/[demo]%20train%20MLP%20with%20dropout,%20L2%20Reg.ipynb)| Jeff | [slides](./slides/Sec4.4_4.6.pdf)
|  9 | 2/14 | Forward & Backward Prop, Vanishing gradient and parameter initialization | d2l [§4.7](./d2l_briefs/4.7_backprop.md), [§4.8](./d2l_briefs/4.8_numerical-stability-and-init.md) | Yang | [slides](./slides/Chapter4.7-4.8.pdf) |
| 10 | 2/16 | DL computation basics | d2l [§5.1](./d2l_briefs/5.1_model-construction.md), [§5.2](./notebooks/5.2_parameter-management.ipynb), [§5.4-5.6](./notebooks/5.4-5.6%20custom-layer,%20file%20IO,%20gpu.ipynb) | Joe | [slides](./slides/Chapter-5.pdf) <br> [notebook](./notebooks/Chapter-5-code-examples.ipynb)
| 11 | 2/21 | CNN basics 1 (Intro, Convolution, Padding & Stride) | d2l [§6.1](./d2l_briefs/6.1_why-cnn.md), [§6.2-§6.3](./notebooks/6.2-6.3%20CNN_1.ipynb) | Annie |[CNN 6.1-6.3.pdf](https://github.com/UA-ASTR502-2022/astr502/files/8130674/CNN.6.1-6.3.pdf) |
| 12 | 2/23 | CNN basics 2 (Channels, Pooling, LeNet) | d2l [§6.4-§6.6](./notebooks/6.4_6.6%20CNN_2.ipynb) | Patrick |
| 13 | 2/28 | Optimization Basics, Convexity | d2l [§11.1](./d2l_briefs/11.1_optimization-intro.md), [§11.2](./d2l_briefs/11.2_convexity.md) | Lily | [slides](./slides/Chapter11.1-11.2.pdf) |
| 14 | 3/2 | ------ Prelim, no lecture today ------ |  |  |
| 15 | 3/14 | Gradient Descent | d2l 11.3-11.5 | Vivian |
| 16 | 3/16 | Optimization algorithm 1 (momentum, adagrad) | d2l 11.6-11.7 | Hayden |
| 17 | 3/21 | Optimization algorithm 2 (RMSProp, Adadelta, Adam) | d2l 11.8-11.10 | Gabriela |
| 18 | 3/23 | Learning Rate decay, Batch Normalization | d2l 11.11, 7.5 | Haley |
| 19 | 3/28 | CNN architecture 1 (AlexNet, VGG) | d2l 7.1-7.2 | Paul |
| 20 | 3/30 | CNN architecture 2 (NiN, GoogLeNet) | d2l 7.3-7.4 | Jake |
| 21 | 4/4 | CNN architecture 3 (ResNet, DenseNet) | d2l 7.6-7.7 | Yi-Hsiu |
| 22 | 4/6 | TBD | |
| 23 | 4/11 | Term Project 1  | |
| 24 | 4/13 | Term Project 2  | |
| 25 | 4/18 | Term Project 3  | |
| 26 | 4/20 | Term Project 4  | |
| 27 | 4/25 | Term Project 5  | |
| 28 | 4/27 | Term Project 6  | |
| 29 | 5/2 | Term Project 7  | |
| 30 | 5/4 | TBD  | |

## Links

- [Lecture Presentation sign up sheet](https://docs.google.com/spreadsheets/d/1fAXCX4KAjm6qUFpbhN5rk-7BbxeYci_f1RwhIoH6z3M/edit#gid=0)
  
- [Selected ML papers in Astronomy](./Term%20Projects/README.md)

- [ML papers in cosmology](https://github.com/georgestein/ml-in-cosmology/blob/master/README.md)
